{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Filtering with food keywords","metadata":{}},{"cell_type":"code","source":"import json\nfrom tqdm import tqdm\n\n# Load COCO annotation file\nwith open(\"/kaggle/input/coco-2017-dataset/coco2017/annotations/captions_train2017.json\", \"r\") as f:\n    coco_data = json.load(f)\n\n# Keywords indicative of food context\nfood_keywords = [\n    \"food\", \"pizza\", \"plate\", \"bowl\", \"table\", \"kitchen\", \"dining\", \"meal\", \"cake\", \"bread\", \"sandwich\",\n    \"lunch\", \"dinner\", \"breakfast\", \"cupcake\", \"cheese\", \"pasta\", \"dish\", \"eating\", \"cook\", \"burger\",\n    \"noodle\", \"chopstick\", \"restaurant\", \"cooking\", \"doughnut\", \"fork\", \"spoon\", \"knife\"\n]\n\n# Convert to lowercase for easier match\nfood_keywords = set(k.lower() for k in food_keywords)\n\n# Step 1: Index image info\nimgid2info = {img['id']: img for img in coco_data['images']}\n\n# Step 2: Group captions by image_id and check if caption contains food-related keyword\nimage_dict = {}\n\nfor ann in tqdm(coco_data['annotations'], desc=\"Filtering food captions\"):\n    img_id = ann['image_id']\n    caption = ann['caption'].lower()\n\n    if any(kw in caption for kw in food_keywords):\n        if img_id not in image_dict:\n            image_info = imgid2info[img_id]\n            image_dict[img_id] = {\n                \"filename\": f\"{img_id:012d}.jpg\",\n                \"url\": f\"http://images.cocodataset.org/train2017/{img_id:012d}.jpg\",\n                \"sentences\": []\n            }\n        image_dict[img_id][\"sentences\"].append({\n            \"raw\": ann['caption'],\n            \"tokens\": ann['caption'].lower().split()\n        })\n\n# Step 3: Drop images with no valid captions or no variety\nfiltered_images = [\n    img for img in image_dict.values()\n    if len(img['sentences']) >= 2\n]\n\n# Step 4: Assign random split (80% train, 10% val, 10% test)\nfrom random import shuffle\nshuffle(filtered_images)\n\nN = len(filtered_images)\nfor i, img in enumerate(filtered_images):\n    if i < int(0.8 * N):\n        img['split'] = 'train'\n    elif i < int(0.9 * N):\n        img['split'] = 'val'\n    else:\n        img['split'] = 'test'\n\n# Step 5: Save as Karpathy-style JSON\nkarpathy_food_path = \"/kaggle/working/coco_food_karpathy.json\"\nwith open(karpathy_food_path, \"w\") as f:\n    json.dump({\"images\": filtered_images}, f, indent=2)\n\nprint(f\"‚úÖ Saved filtered food-related COCO captions to: {karpathy_food_path}\")\nprint(f\"üìä Total food images: {len(filtered_images)}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T20:52:39.426076Z","iopub.execute_input":"2025-05-20T20:52:39.426424Z","iopub.status.idle":"2025-05-20T20:52:47.307887Z","shell.execute_reply.started":"2025-05-20T20:52:39.426392Z","shell.execute_reply":"2025-05-20T20:52:47.306719Z"}},"outputs":[{"name":"stderr","text":"Filtering food captions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 591753/591753 [00:03<00:00, 160677.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Saved filtered food-related COCO captions to: /kaggle/working/coco_food_karpathy.json\nüìä Total food images: 23251\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Preprocess into hdf5\nfor pretrain","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport h5py\nimport numpy as np\nfrom collections import Counter\nfrom random import seed, choice, sample\nfrom PIL import Image\nfrom tqdm import tqdm\nimport torchvision.transforms as transforms\n\n# Konfigurasi\njson_path = \"/kaggle/working/coco_food_karpathy.json\"\nimage_folder = \"/kaggle/input/coco-2017-dataset/coco2017/train2017\"\noutput_folder = \"/kaggle/working/pretrain_coco_food\"\nos.makedirs(output_folder, exist_ok=True)\n\ncaptions_per_image = 5\nmin_word_freq = 5\nmax_len = 50\nresized_size = 256\n\n# Tokenizer\ndef tokenize(sentence):\n    return sentence.lower().strip().split()\n\n# Load JSON\nwith open(json_path, 'r') as f:\n    data = json.load(f)\n\n# Word frequency\nword_freq = Counter()\nfor img in data['images']:\n    for cap in img['sentences']:\n        word_freq.update(cap['tokens'])\n\n# Word map\nwords = [w for w in word_freq.keys() if word_freq[w] >= min_word_freq]\nword_map = {k: v+1 for v, k in enumerate(words)}\nword_map['<unk>'] = len(word_map) + 1\nword_map['<start>'] = len(word_map) + 1\nword_map['<end>'] = len(word_map) + 1\nword_map['<pad>'] = 0\n\n# Save word map\nwith open(os.path.join(output_folder, \"wordmap_coco_food.json\"), \"w\") as j:\n    json.dump(word_map, j)\n\nprint(\"‚úÖ Wordmap saved:\", len(word_map), \"words\")\n\n# Preprocess image\ndef load_image(img_path):\n    img = Image.open(img_path).convert(\"RGB\")\n    tf = transforms.Compose([\n        transforms.Resize((resized_size, resized_size)),\n        transforms.ToTensor()\n    ])\n    return tf(img)\n\n# Proses per split\nfor split in ['train', 'val', 'test']:\n    split_imgs = [img for img in data['images'] if img['split'] == split]\n\n    with h5py.File(os.path.join(output_folder, f\"{split}_images_coco_food.hdf5\"), 'w') as h:\n        h.attrs['captions_per_image'] = captions_per_image\n        images = h.create_dataset('images', (len(split_imgs), 3, resized_size, resized_size), dtype='uint8')\n\n        encoded_captions = []\n        caption_lengths = []\n\n        for i, img in enumerate(tqdm(split_imgs, desc=f\"{split} images\")):\n            img_path = os.path.join(image_folder, img[\"filename\"])\n            try:\n                img_tensor = load_image(img_path) * 255\n                images[i] = img_tensor.byte()\n            except:\n                print(\"‚ö†Ô∏è Skip corrupt image:\", img[\"filename\"])\n                continue\n\n            caps = [c[\"tokens\"] for c in img[\"sentences\"] if len(c[\"tokens\"]) <= max_len]\n            if len(caps) == 0:\n                continue\n\n            if len(caps) < captions_per_image:\n                caps = caps + [choice(caps) for _ in range(captions_per_image - len(caps))]\n            else:\n                caps = sample(caps, k=captions_per_image)\n\n            for c in caps:\n                enc = [word_map['<start>']] + [word_map.get(w, word_map['<unk>']) for w in c] + [word_map['<end>']]\n                enc += [word_map['<pad>']] * (max_len + 2 - len(enc))\n                encoded_captions.append(enc)\n                caption_lengths.append(len(c) + 2)\n\n    # Save\n    with open(os.path.join(output_folder, f\"{split}_captions_coco_food.json\"), \"w\") as f:\n        json.dump(encoded_captions, f)\n    with open(os.path.join(output_folder, f\"{split}_caplength_coco_food.json\"), \"w\") as f:\n        json.dump(caption_lengths, f)\n\nprint(\"‚úÖ Preprocessing done and saved to:\", output_folder)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T20:56:50.315750Z","iopub.execute_input":"2025-05-20T20:56:50.316087Z","iopub.status.idle":"2025-05-20T21:04:38.585549Z","shell.execute_reply.started":"2025-05-20T20:56:50.316060Z","shell.execute_reply":"2025-05-20T21:04:38.584201Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Wordmap saved: 4718 words\n","output_type":"stream"},{"name":"stderr","text":"train images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18600/18600 [06:03<00:00, 51.23it/s]\nval images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2325/2325 [00:45<00:00, 51.17it/s]\ntest images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2326/2326 [00:44<00:00, 52.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Preprocessing done and saved to: /kaggle/working/pretrain_coco_food\n","output_type":"stream"}],"execution_count":2}]}