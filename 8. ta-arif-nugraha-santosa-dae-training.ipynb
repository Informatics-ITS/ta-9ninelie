{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Filtering dan Re-save Dataset","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.nn.utils.rnn import pad_sequence\n\ndae_data = torch.load('/kaggle/input/dae-preprocessed/dae_preprocessed.pt')\ninput_seqs = dae_data['input_seqs']\ntarget_seqs = dae_data['target_seqs']\nword_map = dae_data['word_map']\n\nmax_target_len = 64  # kamu bisa sesuaikan (64 cukup untuk caption)\nnew_input, new_target = [], []\nfor inp, tgt in zip(input_seqs, target_seqs):\n    tgt_len = (tgt != word_map['<pad>']).sum().item()\n    if tgt_len <= max_target_len:\n        new_input.append(inp)\n        new_target.append(tgt)\ninput_seqs_pad = pad_sequence(new_input, batch_first=True, padding_value=word_map['<pad>'])\ntarget_seqs_pad = pad_sequence(new_target, batch_first=True, padding_value=word_map['<pad>'])\nprint(\"Setelah filtering, jumlah sample:\", input_seqs_pad.shape[0])\n\n# Re-save\ntorch.save({\n    'input_seqs': input_seqs_pad,\n    'target_seqs': target_seqs_pad,\n    'word_map': word_map\n}, 'dae_preprocessed_filtered.pt')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-14T11:53:44.207636Z","iopub.execute_input":"2025-06-14T11:53:44.208437Z","iopub.status.idle":"2025-06-14T11:53:44.585329Z","shell.execute_reply.started":"2025-06-14T11:53:44.208385Z","shell.execute_reply":"2025-06-14T11:53:44.584413Z"}},"outputs":[{"name":"stdout","text":"Setelah filtering, jumlah sample: 6480\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"markdown","source":"## DataLoader","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass DAEDataset(Dataset):\n    def __init__(self, data_path):\n        data = torch.load(data_path)\n        self.input_seqs = data['input_seqs']\n        self.target_seqs = data['target_seqs']\n    def __len__(self):\n        return self.input_seqs.size(0)\n    def __getitem__(self, idx):\n        return self.input_seqs[idx], self.target_seqs[idx]\n\nbatch_size = 32\ntrain_dataset = DAEDataset('/kaggle/working/dae_preprocessed_filtered.pt')\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T11:53:46.810046Z","iopub.execute_input":"2025-06-14T11:53:46.810740Z","iopub.status.idle":"2025-06-14T11:53:46.891726Z","shell.execute_reply.started":"2025-06-14T11:53:46.810717Z","shell.execute_reply":"2025-06-14T11:53:46.890890Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Model DAE LSTM ","metadata":{}},{"cell_type":"code","source":"class DAELSTM(nn.Module):\n    def __init__(self, vocab_size, embed_dim=300, hidden_dim=512, pad_idx=0):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n        self.encoder = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.decoder = nn.LSTM(embed_dim, hidden_dim*2, batch_first=True)\n        self.fc = nn.Linear(hidden_dim*2, vocab_size)\n    def forward(self, src, tgt):\n        emb_src = self.embedding(src)\n        _, (h, c) = self.encoder(emb_src)  # h, c: [2, B, 512]\n        # Gabungkan arah forward dan backward (biLSTM) untuk jadi 1 state [1, B, 1024]\n        h_cat = torch.cat([h[0], h[1]], dim=-1).unsqueeze(0)  # [1, B, 1024]\n        c_cat = torch.cat([c[0], c[1]], dim=-1).unsqueeze(0)  # [1, B, 1024]\n        emb_tgt = self.embedding(tgt[:, :-1])  # input target tanpa <end>\n        dec_out, _ = self.decoder(emb_tgt, (h_cat, c_cat))\n        out = self.fc(dec_out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T11:53:51.764539Z","iopub.execute_input":"2025-06-14T11:53:51.765025Z","iopub.status.idle":"2025-06-14T11:53:51.772669Z","shell.execute_reply.started":"2025-06-14T11:53:51.764991Z","shell.execute_reply":"2025-06-14T11:53:51.771837Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Main Loop","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\nimport numpy as np\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nvocab_size = len(word_map)\npad_idx = word_map['<pad>']\n\nmodel = DAELSTM(vocab_size=vocab_size, embed_dim=300, hidden_dim=512, pad_idx=pad_idx).to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n\nn_epochs = 10\nbest_loss = float('inf')\n\nfor epoch in range(n_epochs):\n    model.train()\n    epoch_loss = 0\n    for inputs, targets in train_loader:\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs, targets)  # (B, T, V)\n        # Shift targets for loss: target[:, 1:] (tanpa <start>)\n        outputs = outputs.reshape(-1, vocab_size)\n        gold = targets[:, 1:].reshape(-1)\n        loss = criterion(outputs, gold)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    avg_loss = epoch_loss / len(train_loader)\n    print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\")\n\n    # Save best\n    if avg_loss < best_loss:\n        best_loss = avg_loss\n        torch.save(model.state_dict(), \"dae_lstm_best.pt\")\n        print(\"Best model saved.\")\n\nprint(\"Training selesai. Best loss:\", best_loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T11:53:54.698489Z","iopub.execute_input":"2025-06-14T11:53:54.698763Z","iopub.status.idle":"2025-06-14T12:07:17.274349Z","shell.execute_reply.started":"2025-06-14T11:53:54.698741Z","shell.execute_reply":"2025-06-14T12:07:17.273468Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 | Loss: 5.5120\nBest model saved.\nEpoch 2 | Loss: 4.6987\nBest model saved.\nEpoch 3 | Loss: 4.2932\nBest model saved.\nEpoch 4 | Loss: 3.9147\nBest model saved.\nEpoch 5 | Loss: 3.5086\nBest model saved.\nEpoch 6 | Loss: 3.0540\nBest model saved.\nEpoch 7 | Loss: 2.5720\nBest model saved.\nEpoch 8 | Loss: 2.0944\nBest model saved.\nEpoch 9 | Loss: 1.6568\nBest model saved.\nEpoch 10 | Loss: 1.2930\nBest model saved.\nTraining selesai. Best loss: 1.293038960748118\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Load","metadata":{}},{"cell_type":"code","source":"# Load for inference\nmodel = DAELSTM(vocab_size=vocab_size, embed_dim=300, hidden_dim=512, pad_idx=pad_idx).to(device)\nmodel.load_state_dict(torch.load(\"/kaggle/working/dae_lstm_best.pt\", map_location=device))\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:18:31.375698Z","iopub.execute_input":"2025-06-14T12:18:31.376468Z","iopub.status.idle":"2025-06-14T12:18:31.653525Z","shell.execute_reply.started":"2025-06-14T12:18:31.376434Z","shell.execute_reply":"2025-06-14T12:18:31.653011Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DAELSTM(\n  (embedding): Embedding(8842, 300, padding_idx=0)\n  (encoder): LSTM(300, 512, batch_first=True, bidirectional=True)\n  (decoder): LSTM(300, 1024, batch_first=True)\n  (fc): Linear(in_features=1024, out_features=8842, bias=True)\n)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import torch\n\ndef decode_caption(model, input_seq, word_map, max_len=64, device='cpu'):\n    model.eval()\n    inv_word_map = {v: k for k, v in word_map.items()}\n    with torch.no_grad():\n        # (1, seq_len)\n        inp = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0).to(device)\n        emb_src = model.embedding(inp)\n        _, (h, c) = model.encoder(emb_src)\n        h_cat = torch.cat([h[0], h[1]], dim=-1).unsqueeze(0)\n        c_cat = torch.cat([c[0], c[1]], dim=-1).unsqueeze(0)\n\n        # Start dengan <start>\n        cur_token = torch.tensor([[word_map['<start>']]], dtype=torch.long).to(device)\n        decoded = []\n        for _ in range(max_len):\n            emb_tgt = model.embedding(cur_token)\n            out, (h_cat, c_cat) = model.decoder(emb_tgt, (h_cat, c_cat))\n            logits = model.fc(out[:, -1])  # Ambil token terakhir\n            next_token = logits.argmax(-1)\n            word = inv_word_map[next_token.item()]\n            if word == '<end>':\n                break\n            decoded.append(word)\n            cur_token = next_token.unsqueeze(0)\n    return ' '.join(decoded)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:21:14.853608Z","iopub.execute_input":"2025-06-14T12:21:14.854169Z","iopub.status.idle":"2025-06-14T12:21:14.860673Z","shell.execute_reply.started":"2025-06-14T12:21:14.854146Z","shell.execute_reply":"2025-06-14T12:21:14.860084Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Load model (pastikan path dan param benar)\nmodel = DAELSTM(vocab_size=len(word_map), embed_dim=300, hidden_dim=512, pad_idx=word_map['<pad>']).to(device)\nmodel.load_state_dict(torch.load(\"/kaggle/working/dae_lstm_best.pt\", map_location=device))\nmodel.eval()\n\n# Inference untuk 5 sample random\nimport random\ndae_data = torch.load('/kaggle/working/dae_preprocessed_filtered.pt')\ninput_seqs = dae_data['input_seqs']\nword_map = dae_data['word_map']\n\nsamples = random.sample(range(len(input_seqs)), 5)\nfor i in samples:\n    inp = input_seqs[i].cpu().numpy()\n    # Hapus padding 0\n    inp = inp[inp != word_map['<pad>']]\n    decoded_caption = decode_caption(model, inp, word_map, max_len=64, device=device)\n    print(f\"\\nSample #{i}\")\n    print(f\"Decoded DAE caption: {decoded_caption}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:21:18.311183Z","iopub.execute_input":"2025-06-14T12:21:18.311698Z","iopub.status.idle":"2025-06-14T12:21:18.751571Z","shell.execute_reply.started":"2025-06-14T12:21:18.311674Z","shell.execute_reply":"2025-06-14T12:21:18.750973Z"}},"outputs":[{"name":"stdout","text":"\nSample #2648\nDecoded DAE caption: i love the idea and the lighting looks just a little too close to the right <unk>\n\nSample #454\nDecoded DAE caption: i just love the crops that you do like <unk> as they have been a fun image\n\nSample #1209\nDecoded DAE caption: i love the colors and the <unk> texture is all around great job\n\nSample #5041\nDecoded DAE caption: i just love the idea and effort for this image to work for me\n\nSample #3396\nDecoded DAE caption: i just love the crops that you do like <unk> as they have been a <unk> <unk>\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import json\n\nresults = []\nfor i in range(len(input_seqs)):\n    inp = input_seqs[i].cpu().numpy()\n    inp = inp[inp != word_map['<pad>']]\n    caption = decode_caption(model, inp, word_map, max_len=64, device=device)\n    results.append({'id': int(i), 'dae_caption': caption})\n\nwith open('dae_lstm_outputs.json', 'w', encoding='utf8') as f:\n    json.dump(results, f, ensure_ascii=False, indent=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:22:15.167953Z","iopub.execute_input":"2025-06-14T12:22:15.168657Z","iopub.status.idle":"2025-06-14T12:23:40.866607Z","shell.execute_reply.started":"2025-06-14T12:22:15.168635Z","shell.execute_reply":"2025-06-14T12:23:40.866050Z"}},"outputs":[],"execution_count":12}]}